0.
0.1 testffmpeg视频播放器项目开发记录
	0.1.1 Build command failed.
		...
		../../../../include\libavutil/error.h:111: error: undefined reference to 'av_strerror'
		
		此处保存下部分异常日志。
		原因是没有引用某一个ffmpeg模块。
		完整日志可以通过，故意不引用某一个ffmpeg模块来查看。

4. 
	4.4 	
		flv 或h264格式的视频没有头部信息。
		就无法获得总的时长。Number of elements in AVFormatContext.streams = 0;
		
		需要调用：avformat_find_stream_info才可以获取头信息，如时长
		
		4.4.2 av_seek_frame(ic,videoStream,pos,AVSEEK_FLAG_BACKWARD|AVSEEK_FLAG_FRAME )
			pos 如何设置。根据总时长吗？(AVFormatContext)ic->duration 
5. 
	5.7 ffmpeg调用MediaCodec实现硬解码			
			硬解码，用的是cpu上面固化的一段芯片，专门用来处理音视频的，硬解码不会大量占用cpu 也不会占用gpu,但解码的帧率是固化的。
			android中硬解码部分没有实现c++接口只实现了java接口，需要c++调用java接口。
		5.7.0 h264_mediacodec
			a，
				avcodec_open2 for video failed!:Invalid argument
			b,开启视频硬解码时，运行在真机设备上,报错：
				avcodec_find_decoder 13 failed!  1 
				#13为codec_id，1为硬解码变量值
				
			分析：同【5.7.1】
		5.7.1 ffmpeg android jni端调用mediaCodec实现硬解码
			https://blog.csdn.net/zhangpengzp/article/details/88943867?
			
			这样就可以打开硬解码了，当然在编译ffmpeg的时候要支持硬解码，请参考ffmpeg 编译android so库文件 后面跟新的部分。 
			参考博文：：
			ffmpeg 编译android so库文件：：
			https://blog.csdn.net/zhangpengzp/article/details/82289224 
6. 
	6.2 
		解码之前可能读取不到宽高。所以在解码之后调用。
		
		视频重采样后，sws_scale = 0，啥原因？
		是这个吗？char *rgb = new char[1920*1080*4];当前测试视频：1280x720
		
		使用课件中的1080.mp4正常视频重采样，当随便更换一个mp4视频，重采样返回h=0;
		
		博文：
		SwsContext、sws_scale缩放失败，或者缩放后视频乱码?
		https://blog.csdn.net/zhangpengzp/article/details/89278513 
		【该博主，图像研究比较深入】值得参考学习。
			解决方案：

			1、可以将宽度设置为linesize[0]，这样就不会乱码了，但存在意外，视频1920*1080的时候太大，也无法显示。

			2、缩放是根据宽度，android平台最好是64倍数，高度也是有相应的限制。为了播放器的 兼容性，最好使用opengl来渲染、或者利用 高效率libyuv 库来进行格式转换显示，libyuv高效转化git地址https://github.com/hurtnotbad/FFmpegDemo。

			具体的 解决方法请参考博客：FFMpeg opengl显示解码avframe 
				【https://blog.csdn.net/zhangpengzp/article/details/89531572】
8. EGL和OpenGLES Shader显示YUV视频
	8.1 
		relate1:视频学习笔记：Android OpenGL渲染YUV420P图像
			https://blog.csdn.net/lidec/article/details/73732369 
			
			Include GLES to CMakeLists in Android NDK
			https://stackoverflow.com/questions/42103942/include-gles-to-cmakelists-in-android-ndk 
		relate2:gitee中demo
			search keyword : opengles yuv
		relate3:ffmpeg opengles yuv
			https://github.com/susirsusir/ffmpeg_yuv
		q0:当前程序配置选项
			opengles 2.0
		q1:eglCreateContext failed! 
			
			context 创建关联的上下文
			const EGLint ctxAttr[] = {
					EGL_CONTEXT_CLIENT_VERSION,1,EGL_NONE
			};
			EGLContext context = eglCreateContext(display,config,EGL_NO_CONTEXT,ctxAttr);
			版本号使用1可以，可能不同平台兼容适配性问题。
			
			但是还有问题：
			glCreateShader 35633 failed!  //35633  => GL_VERTEX_SHADER
		q2:以上加载正常，但还是未能显示。
			android 使用openGL_ES 真机上无法显示纹理是什么原因？
			https://bbs.csdn.net/topics/390369747  
			gpu相关设置需要打开？
			
			android jni调用opengl es fbo部分机型没有画面问题 
			https://blog.csdn.net/u010302327/article/details/80339078 
			
			参考博客：
			MP4视频播放问题（有声音无图像）分析与解决——FFmpeg视频处理教程
			https://blog.csdn.net/qq_37868757/article/details/112851978
			启发是编码格式问题。
			原视频1080.mp4::Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080
			paiDuiGe.mp4::  Stream #0:0(eng): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p ,1280x720
			
		q3 图像显示不出来
			设置的宽高要和实际视频保持一致，否则显示花屏图像。继续转到【q5】
		q4 用android的native surface来显示视频画面无效
			https://bbs.csdn.net/topics/380267218?list=25609635 
		q5 经过以上q{n}处理，在android5.1的手机上能正常显示，但在android9的手机上就无法显示图像。
			在android9上初步查看，当前所加的日志都正常打印。是否还有相关日志没加呢？窗口相关的日志没有加。
			q5.1 是否和编译脚本中--sysroot所指定的android平台版本有关。android-21
			
			验证a：在android-24,即android版本7，模拟器，x86_64,(编译工具ffmpeg3.4.8,ndk-r13b)
				该模拟器：emulated performance 选项中graphics:选择
				Automatic 			#ok
				Hardware - GLES 2.0	#ok
				Software - GLES 1.1 #当然模拟器选择该项时，运行提示opengles api没有实现，且创建链接程序失败。
			验证b：在android-23,即android版本6.0，模拟器，x86,(编译工具ffmpeg3.4.8,ndk-r13b)
				该模拟器：emulated performance 选项中graphics:选择
				Automatic 			#模拟器无法启动
				Hardware - GLES 2.0	#模拟器无法启动
				Software - GLES 1.1 #模拟器正常启动，且图像显示，播放速度默认也正常。
			初步猜测结论：编译ffmpeg时选择的android api级别决定了，影响在高地版本上运行。
				低android api版本编译处理的so,无法在高版本上运行，虽然初步日志正常，但图像不显示。尚需要进一步验证。
				
			Hardware - GLES 2.0:在模拟器上失败：
			ERROR: Could not initialize OpenglES emulation, use '-gpu off' to disable it.
			Emulator: Process finished with exit code -1073741819 (0xC0000005)
			
			androidstudio3.5创建avd时，没有‘-gpu off’选项。
				选项中graphics只要不使用Hardware - GLES*就可以
				
			打印：
			reqGlEsVersion = 20000
			OpenGLRenderer: Initialized EGL, version 1.4
			同样的值但在s500上【eglCreateContext failed! error:12293】
			
			eglCreateContext failed! error:12293
			对应错误码（/EGL/egl.h）：EGL_BAD_CONFIG			0x3005
			对应在线文档：
				EGL_BAD_CONFIG：
				An EGLConfig argument does not name a valid EGL frame buffer configuration.
			#XEGL.cpp
	8.x
		EGL是显示用的。
9. 视频播放器项目实战一 需求和设计模式
10. 视频播放器项目实战二 音视频解码解封装
	10.1 项目创建权限ABI和CMake相关库和头文件配置~1【程序员教程吧 www.cxyjc8.com】
		android 库是获取窗口句柄的。
	10.3 FFDemux的Open实现打开媒体文件~1【程序员教程吧 www.cxyjc8.com】
	10.5. 完成XThread线程类IDemux继承后在线程中读取帧数据~1【程序员教程吧 www.cxyjc8.com】
		using namespace std;//不要放在头文件中，要放在cpp实现文件中，应为头文件可能会被其它头文件引用（可能重复等），头文件不可控，而cpp是可控的、自己写的。
	10.7. 观察者Observer模式的代码实现并使用IDemux进行测试~1【程序员教程吧 www.cxyjc8.com】
		c++11 中 vector size()每次调用，会遍历一遍，效率比较低
	10.11. 封装FFDecode解码的Send和Recv接口~1【程序员教程吧 www.cxyjc8.com】
		a,早期ffmpeg版本,音频视频解码是分开的。现在的是在一起的
		 现在使用future模型，同生产者消费者模型。
		b，AVCodecContext 多线程解码
			codec->thread_count = 8;//多线程解码
11 video project chapter3
	q1：图像无法显示问题同【8】中记录分析解决。
	q2,图像能正常显示后，感觉想2倍快进一样，是哪里设置出问题了吗？
	11.1. IVideoView显示模块架构讲解和代码创建~1
		显示部分要与解码部分独立开，独立初始化.
		a，eglChooseConfig
			part api doc:
			If this value is zero, color buffers with the smallest blue component size are preferred. Otherwise, color buffers with the largest blue component of at least the specified size are preferred.
			如何理解？
			google翻译如下：
			如果此值为零，则首选具有最小蓝色分量大小的颜色缓冲区。否则，具有至少指定大小的最大蓝色分量的颜色缓冲区是首选。
	11.3. XShader基于yuv420p的初始化Init代码完成并测试~1
		如果做多路视频，需要多个XShader，不能做单例模式了。但可以将多路视频写到同一个egl中。
		
	11.8 完成了IAudioPlay和SLAudioPlay的音频播放环境初始化~1
		a,SLAudioPlay::StartPlay
			定义pcm时，sample_rate *1000是否正确？
			验证：FFDemux::GetAPara sample_rate=44100 #打印值
					而OpenSLES.h中定义的 SL_SAMPLINGRATE_44_1为44100000。保持一致需要乘以1000
		b,音频为什么需要重采样？
			也有不需要重采样。
			当前使用ffmpeg时，采用了重采样，ffmeng定义的音频
	11.9 
		使用opensl播放音频，
		也可以使用qt播放音频。
	11.11. 完成硬解码并完成NV21和NV12格式的shader显示编写~1
		a，硬解码部分和软解码部分的shader不一致
		
		b,查看视频像素格式
			ffmpeg中：
			libavutil/pixfmt.h AVPixelFormat
		c,硬解码要注册
			JNI_OnLoad(JavaVM *vm,void *res)
				FFDecode::InitHard(vm);
					av_jni_set_java_vm(vm,0);
		d,targetSdkVersion 21 #指定为21暂且不需要配置动态权限申请代码。
	11.12. 解决android8.0下opengles不能播放的问题和音频播放的回音问题~1
		a，android8.0下画面不能显示问题的解决
			//android 8.0 需要设置
			setRenderer( this );
		b,声音出现了重音
			在以下函数中调用了两次代码
			Java_xplay_xplay_MainActivity_stringFromJNI
			抽取到JNI_OnLoad函数中，保证调用一次即可解决当前问题
			
12. 视频播放器项目实战四 完成架构解决同步和seek
	12.1. 完成facade模式的IPlayer并实现Open接口.~1
		a,IPlay对象可能有多个，如果开放为多窗口播放的话。
		b,第二次打开IPlay时，上一次的是清理掉，还是获取上一次的内容
		c,使用[门面模式]就是内部的元素不要用户知道，用户只知道IPlay。好处是，细节更换，用户代码不需要调整。
	12.2. 完成Iplayer开始播放和窗口初始化接口~1
		音频先启动，先开启播放；音频先于视频，因为视频可以快进或后退，音频对用于而言是高度敏感的。
	12.
		a，使用建造者模式。
		b,如果要移植到到qt平台，更换IAudioPlay的具体qt实现即可。
	12.4. 完成IPlayerProxy代理模式并进行测试架构搭建完成~1
		a,IPlayer中的函数都要在代理类IPlayerProxy中实现。
		a2，以后二者之一有添加函数，对应的另一个也需要添加。
		a3,代理类继承主题接口类
		a4，当有多个窗口IPlayer时,还是通过一个IPlayerProxy代理管理处理。【视频多路处理。】
	12.5. 统一换算pts为毫秒使用IPlayer完成音视频同步播放~1
		a,	音视频同步
			.设定基准事件音视频同步 #只针对多路视频
			·视频同步音频	#采用该方案。视频可以快进或后退
			·音频同步视频	#音频高度敏感，无法控制。
		a2,用IPlayer中间者控制同步，避免音频、视频代码耦合
			在独立的线程中处理同步。
		a3，音频和视频的时间单位基数是不一致的，需要换算为一致的时间基数
		a4,要在IDecode中对视频同步音频处理
			同时要尽可能在接口类中完成通过处理。
		a5,配置好后，观看播放字幕，并没有同步。
			打印：
			IDecode::Main() enter,current synPts = 67964,pts = 0
			视频的pts为0.
			分析：是{IDecode::Main()中获取解码后数据的函数{RecvFrame()}之后未对pts赋值}
	12.6. IDemux&FFdemux线程安全和Close清理函数编写~1
		a,FFDemux对成员共享变量{AVFormatContext *ic}加锁。
		b,FFDemux添加Close清理函数，每次Open时都先调用该清理函数。
	12.7. FFdecode和FFResample线程安全处理和Close清理函数编写~1
		锁使用原则：近晚调用，尽早释放。
	12.11. XTexture和GLVideoView的线程安全和清理函数编写~1
		a,清理对象的原则，对象由谁创建，就由谁来清理。
			如：XTexture::Create
		b,析构函数要放到virtual 函数指针中，通过父类指针才可以调用到子类的析构函数。
x,新增待实现内容
	x1,字幕如何显示
y,运行在真机s500（android5.1）上失败。
	y1,XLOGE("eglCreateContext failed!");
		同【8.1 - q5】问题
	